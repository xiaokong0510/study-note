# 05-MySQL 中的锁

课程链接：

- [MySQL 实战 45 讲 06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？](https://time.geekbang.org/column/article/69862)
- [MySQL 实战 45 讲 07 | 行锁功过：怎么减少行锁对性能的影响？](https://time.geekbang.org/column/article/70215)

数据库锁设计的初衷是处理并发问题，内容包括：
- 全局锁
- 表级锁
  - 表锁
  - 元数据锁
- 行锁
  - 两阶段锁
  - 死锁和死锁检测

## 全局锁

给整个数据库实例加锁，整个数据库处于只读状态，客户端断开的时候自动释放。命令：

```bash
# FTWRL
Flush tables with read lock 

# 释放锁
unlock tables
```

加全局锁后，以下语句会被阻塞：
- 数据定义语句（DDL，包括建表、修改表结构等）
- 数据操作语句（DML，数据的增删改）
- 更新类事务的提交语句

### 全库逻辑备份

全局锁的典型使用场景是，做**全库逻辑备份**。

需要保证备份的得到的库是一个逻辑时间点，否则数据可能会不一致。通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。但是备份过程中如果整个库完全处于只读状态，会影响到业务。

另外一种方式，在可重复读隔离级别下开启一个事务也能够拿到一致性视图。官方自带的逻辑备份工具 `mysqldump`， 使用参数`-single-transaction`，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。

有一致性视图功能，为什么还需要 FTWRL ？

因为**需要引擎要支持这个隔离级别**。对于不支持事务的引擎比如 MyISAM，如果备份过程中有更新，总是只能取到最新的数据，就破坏了备份的一致性。

使用 `set global readonly=true` 也可以让全库进入只读状态，但还是会建议用 FTWRL 方式，原因：

- readonly 的值可能会被用来做其他逻辑，比如用来判断一个库是主库还是备库，修改 global 变量的方式影响面更大；
- 在异常处理机制上有差异。执行 FTWRL 命令之后由于客户端发生异常断开，全局锁会自动释放；而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态

## 表级锁

### 表锁

语法：

- 加表锁：`lock tables ... read/write`。read 是共享锁， write 是排它锁。
- 释放锁：`unlock tables`

特点：不仅会限制别的线程的读写，也限定了本线程接下来的操作对象。

例如在某个线程 A 中执行 `lock tables t1 read, t2 write;`则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 `unlock tables` 之前，也只能执行读 t1、读写 t2 的操作，也不能访问其他表。

### MDL

**元数据锁**（metadata lock，MDL）是 server 层的锁，也是表级锁，主要用于隔离 DML 和 DDL 操作之间的干扰。在 MySQL 5.5 版本中引入了 MDL，不需要显式使用，在访问一个表的时候会被自动加上。用于保证读写的正确性。

- 当对一个表做增删改查操作的时候，加 MDL 读锁；
- 当要**对表做结构变更操作**的时候，加 MDL 写锁；
- 读锁之间不互斥，加读锁则所有线程可正常读元数据，不影响增删改查操作，只是不能修改表结构；
- 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。加写锁则只有拥有锁的线程可以读写元数据，也就是修改表结构，其它线程不能执行任何操作，包括修改表结构与增删改查。

事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，**而会等到整个事务提交后再释放。**

###  如何安全给表加字段

一个案例：给一个小表加个字段导致整个库挂了。

![image-20221110230043373](http://image.kongxiao.top/20221110230051.png)

1. session A 先启动，这时候会对表 t 加一个 MDL 读锁；
2. 由于 session B 需要的也是 MDL 读锁，因此可以正常执行；
3. session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞；
4. 之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了；
5. 如果某个表上的查询语句频繁，而且客户端有重试机制，即超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。

>参考文章：[mysql MDL读写锁阻塞，以及online ddl造成的“插队”现象](https://blog.csdn.net/q2878948/article/details/96430129)
>
>申请 MDL 锁的操作会形成一个队列，**队列中写锁获取优先级高于读锁**。一旦出现写锁等待，不但当前操作会被阻塞，同时还会阻塞后续该表的所有操作。事务一旦申请到 MDL 锁后，直到事务执行完才会将锁释放

如何安全给表加字段：

- 首先要解决长事务，事务不提交，就会一直占着 MDL 锁。查到当前执行中的事务：`SELECT * FROM information_schema.innodb_trx`。如果要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务；

- 要变更一个数据量不大的热点表，这时 kill 未必管用，因为新的请求马上就来了。可以在 `alter table` 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后再通过重试命令重复这个过程。

## 行锁

锁住整个表的影响面太大，需要更细粒度的锁。

MySQL 的行锁是在引擎层由各个引擎自己实现的。**MyISAM 仅支持表锁，而 InnoDB 引擎支持行锁。**

行锁的实现是通过给索引上的索引项添加锁实现的，故只有当执行的脚本走索引时，InnoDB 才会使用行锁，否则InnoDB 只能使用元数据锁 MDL。

### 两阶段锁

两阶段锁协议：在 InnoDB 事务中，行锁是在语句执行时才加上的，不是事务开始就加上，但释放是统一在事务结束时才释放。

**对于高并发的行记录的操作语句可以尽可能的安排到最后面，以减少锁等待的时间，提高并发性能。**

### 死锁和死锁检测

死锁：当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态。

当出现死锁以后，有两种策略：

- 一是直接进入等待，直到超时。超时时间可以通过参数 `innodb_lock_wait_timeout` 来设置，默认50 s。对于在线服务来说，这个等待时间往往是无法接受的；但是超时时间设置太短的话，会出现很多误伤。
- 二是发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。参数 `innodb_deadlock_detect` 默认为 on，表示开启这个逻辑。

主动死锁检测有额外负担。每当一个事务被锁时，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。

减少死锁的主要方向，就是控制访问相同资源的并发事务量。

### 热点行更新

如果所有事务都要更新同一行，每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，时间复杂度是 O(n) 。

假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此会看到 CPU 利用率很高，但是每秒却执行不了几个事务。

解决策略：

1. 确保业务上不会产生死锁，直接将死锁检测关闭，弊端是可能会出现大量的超时，对业务有损的；
2. 在数据库中间件中统一对更新同一行的请求进行排队，控制并发度；
3. 拆行，将一行拆成逻辑上的多行来减少锁冲突；有点分段锁的意思，但是需要根据业务逻辑做详细设计。


---

思考题 1： 备份一般都会在备库上执行，在用 `–single-transaction` 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象？

```sql
# 设置 RR 隔离级别 
Q1: SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
# 启动事务,得到一个一致性视图
Q2: START TRANSACTION  WITH CONSISTENT SNAPSHOT；
/* other tables */
# 设置一个保存点
Q3: SAVEPOINT sp;
/* 时刻 1 */
# 拿到表结构
Q4: show create table `t1`;
/* 时刻 2 */
# 导出数据
Q5: SELECT * FROM `t1`;
/* 时刻 3 */
# 回滚到 SAVEPOINT sp，释放锁
Q6: ROLLBACK TO SAVEPOINT sp;
/* 时刻 4 */
/* other tables */
```

分析以上 4 个不同时刻，DDL 从主库传过来的效果。

答案：

1. 如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构；
2. 如果在“时刻 2”到达，则表结构被改过，Q5 执行的时候，报 `Table definition has changed, please retry transaction`，现象：mysqldump 终止；
3. 如果在“时刻 2”和“时刻 3”之间到达，mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。
4. 从“时刻 4”开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 前的表结构。

----

思考题 2：如果要删除一个表里面的前 10000 行数据，以下哪种方法更好：

- 第一种，直接执行 delete from T limit 10000
- 第二种，在一个连接中循环执行 20 次 delete from T limit 500
- 第三种，在 20 个连接中同时执行 delete from T limit 500

答案：

- 第二种方式更好。串行化执行，将相对长的事务分成多次相对短的事务，则每次事务占用锁的时间相对较短。
- 第一种方式：单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。
- 第三种方式：人为自己制造锁竞争，加剧并发量。